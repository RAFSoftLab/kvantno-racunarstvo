{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72372877",
   "metadata": {},
   "source": [
    "## Minimalna dvokubitna QBM\n",
    "\n",
    "Kvantna Born mašina (QBM) je generativni kvantni model mašinskog učenja koji uči raspodele verovatnoća koristeći Bornovo pravilo. QBM-u se zadaje ciljana raspodela, a zatim model podešava parametre  kvantnog kola tako da raspodela merenja postane što sličnija zadatoj. Ova vežba prikazuje dvokubitni QBM sa jednim varijacionim parametrom.\n",
    "\n",
    "![2-qubit-QBM](images/2-qubit-QBM.png)\n",
    "\n",
    "Kvantno kolo modela sastoji se od:\n",
    "\n",
    "1. `RY(θ)` rotacije prvog kubita.  \n",
    "2. `CX(0→1)` operacije spletanja  kubita.  \n",
    "3. Merenja u standardnoj bazi.  \n",
    "\n",
    "Dobijeno stanje je:\n",
    "\n",
    "$$\n",
    "\\cos\\!\\left(\\tfrac{\\theta}{2}\\right)\\lvert 00\\rangle \\;+\\; \\sin\\!\\left(\\tfrac{\\theta}{2}\\right)\\lvert 11\\rangle\n",
    "$$\n",
    "\n",
    "tako da se ishodi merenja svode na:\n",
    "\n",
    "$$\n",
    "P_{\\text{model}}(00) = \\cos^2\\!\\left(\\tfrac{\\theta}{2}\\right), \\qquad\n",
    "P_{\\text{model}}(11) = \\sin^2\\!\\left(\\tfrac{\\theta}{2}\\right).\n",
    "$$\n",
    "\n",
    "Ovaj model može da predstavi raspodelu verovatnoća merenja rezultata $\\{00,11\\}$.\n",
    "\n",
    "## Ključne funkcije\n",
    "\n",
    "- **`vqc(theta, plot=False)`**  \n",
    "  Generiše varijaciono kvantno kolo, izvršava ga na simulatoru i vraća dobijenu raspodelu verovatnoća.  \n",
    "\n",
    "- **Funkcije odstupanja (loss)**  \n",
    "  Poredi modeliranu raspodela $p_{\\text{model}}$ sa ciljnom raspodelom $p_{\\text{target}}$.  \n",
    "\n",
    "  - `l1_loss(p_model, t_dist)`  \n",
    "    Računa $\\ell_1$ (Manhetn) rastojanje:  \n",
    "    $$\n",
    "    L_1(p_{\\text{model}}, p_{\\text{target}}) \\;=\\; \n",
    "    \\sum_{x} \\big|\\, p_{\\text{model}}(x) - p_{\\text{target}}(x)\\,\\big|\n",
    "    $$\n",
    "  \n",
    "  - `l2_loss(p_model, t_dist)`  \n",
    "    Računa $\\ell_2$ (Euklidsko) rastojanje:  \n",
    "    $$\n",
    "    L_2(p_{\\text{model}}, p_{\\text{target}}) \\;=\\;\n",
    "    \\sqrt{\\;\\sum_{x} \\big( p_{\\text{model}}(x) - p_{\\text{target}}(x) \\big)^2}\n",
    "    $$\n",
    "\n",
    "- **`basic_optimizer(loss_fn, t_dist, step_size, max_iter)`**  \n",
    "  Izvršava jednostavnu optimizacionu petlju:  \n",
    "  - Počinje od $\\theta = 0$.  \n",
    "  - Postepeno povećava $\\theta$.  \n",
    "  - Procenjuje raspodelu i odstupanje u odnosu na ciljnu raspodelu.  \n",
    "  - Zaustavlja se kada odstupanje počne da raste.  \n",
    "\n",
    "---\n",
    "\n",
    "## Zadatak\n",
    "\n",
    "1. Pokrenuti program i optimizovati $\\theta$ za zahtevanu ciljnu raspodelu:  \n",
    "   `t_dist = {'00': 0.3, '11': 0.7}`  \n",
    "\n",
    "2. Posmatrati kako optimizator podešava $\\theta$ da minimizuje odstupanje.  \n",
    "3. Zameniti `t_dist` drugim raspodelama nad $\\{00,11\\}$ (npr. `{'00': 0.5, '11': 0.5}`) i uporediti rezultate.  \n",
    "4. Probati i `l1_loss` i `l2_loss` da bi se videlo kako se njihove metrike razlikuju.  \n",
    "\n",
    "## Očekivani rezultat\n",
    "\n",
    "- Graf koji prikazuje kako se odstupanje smanjuje tokom optimizacije.  \n",
    "- Dijagram kola za obučeni QBM.  \n",
    "- Dvostruki stubični dijagram $p_{\\text{model}}$ i $t_{\\text{dist}}$ za vizuelnu proveru poklapanja.  \n",
    "- Ispis optimizovanog parametra i broja iteracija.  \n",
    "\n",
    "## Eksperimenti\n",
    "\n",
    "- Proširiti kolo tako da može da pokrije verovatnoće stanja $\\lvert 01\\rangle$ i $\\lvert 10\\rangle$.  \n",
    "- Iz Pajton biblioteke primeniti gradijentnu metodu ažuriranja $\\theta$.  \n",
    "- Istražiti kako broj izvršavanja programa (shots) utiče na naučenu vrednost $\\theta$ i konačno odstupanje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63374d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.visualization import plot_distribution\n",
    "from qiskit.visualization import circuit_drawer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def vqc(theta, plot=False):\n",
    "    \"\"\"\n",
    "    Creates and runs a simple 2-qubit variational quantum circuit.\n",
    "\n",
    "    Applies an RY rotation by angle `theta` on qubit 0 followed by a CNOT gate to entangle qubit 0 and 1.\n",
    "    The circuit is measured, optionally plotted, and executed on a simulator.\n",
    "\n",
    "    Args:\n",
    "        theta (float): Rotation angle for the RY gate on qubit 0.\n",
    "        plot (bool): If True, displays the circuit diagram.\n",
    "\n",
    "    Returns:\n",
    "        dict: Probability distribution of measurement outcomes (bitstrings).\n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(2,2)\n",
    "    \n",
    "    # set state       \n",
    "    qc.ry(theta, 0)\n",
    "    qc.cx(0, 1)\n",
    "\n",
    "    qc.barrier()\n",
    "    qc.measure(range(2), range(2))\n",
    "    if plot:\n",
    "        display(circuit_drawer(qc, output=\"mpl\"))\n",
    "    \n",
    "    # -- run the program on the simulator --\n",
    "    simulator = AerSimulator()\n",
    "    result = simulator.run(qc, shots=1000).result()\n",
    "    counts = result.get_counts(qc)\n",
    "\n",
    "    # convert counts to probability distribution\n",
    "    total = sum(counts.values())\n",
    "    p_model = {k: v / total for k, v in counts.items()}\n",
    "    \n",
    "    return p_model\n",
    "\n",
    "def l1_loss(p_model, t_dist):\n",
    "    \"\"\"\n",
    "    Computes the L1 loss (Manhattan distance) between two probability distributions.\n",
    "\n",
    "    The L1 loss is the sum of absolute differences between corresponding probabilities \n",
    "    in the model and target distributions. Missing keys are treated as zero.\n",
    "\n",
    "    Args:\n",
    "        p_model (dict): The predicted/model probability distribution.\n",
    "        t_dist (dict): The target/reference probability distribution.\n",
    "\n",
    "    Returns:\n",
    "        float: Total L1 loss between the two distributions.\n",
    "    \"\"\"\n",
    "    keys = set(p_model.keys()).union(t_dist.keys())\n",
    "    loss = 0.0\n",
    "    for k in keys:\n",
    "        model_prob = p_model.get(k, 0.0)    # use 0.0 if key not found\n",
    "        target_prob = t_dist.get(k, 0.0)    # use 0.0 if key not found\n",
    "        diff = abs(model_prob - target_prob)\n",
    "        loss += diff\n",
    "    return loss\n",
    "\n",
    "def l2_loss(p_model, t_dist):\n",
    "    \"\"\"\n",
    "    Computes the L2 loss (Euclidean distance) between two probability distributions.\n",
    "\n",
    "    The L2 loss is the square root of the sum of squared differences between corresponding \n",
    "    probabilities in the model and target distributions. Missing keys are treated as zero.\n",
    "\n",
    "    Args:\n",
    "        p_model (dict): The predicted/model probability distribution.\n",
    "        t_dist (dict): The target/reference probability distribution.\n",
    "\n",
    "    Returns:\n",
    "        float: Total L2 loss between the two distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    keys = set(p_model.keys()).union(t_dist.keys())\n",
    "    loss = 0.0\n",
    "    for k in keys:\n",
    "        model_prob = p_model.get(k, 0.0)    # use 0.0 if key not found\n",
    "        target_prob = t_dist.get(k, 0.0)    # use 0.0 if key not found\n",
    "        diff = model_prob - target_prob\n",
    "        loss += diff ** 2\n",
    "    return loss ** 0.5   # square root for L2\n",
    "\n",
    "\n",
    "def basic_optimizer(loss_fn, t_dist, step_size=0.1, max_iter=100):\n",
    "    \"\"\"\n",
    "    Optimizes the rotation angle theta to minimize the loss \n",
    "    between the VQC output distribution and a target distribution.\n",
    "\n",
    "    The function incrementally increases theta, evaluates the VQC output, \n",
    "    and computes the loss against the target. Optimization stops when \n",
    "    the loss increases, indicating a minimum has been passed.\n",
    "\n",
    "    Args:\n",
    "        loss_fn: loss function name\n",
    "        t_dist (dict): Target probability distribution.\n",
    "        step_size (float): Increment for theta in each iteration.\n",
    "        max_iter (int): Maximum number of optimization steps.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Lists of theta values and corresponding losses.\n",
    "    \"\"\"\n",
    "    theta = 0.0\n",
    "    losses = []\n",
    "    thetas = []\n",
    "\n",
    "    prev_loss = None\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # get model distribution from VQC at current theta\n",
    "        p_model = vqc(theta)\n",
    "\n",
    "        # compute L1 loss\n",
    "        loss = loss_fn(p_model, t_dist)\n",
    "\n",
    "        # check if loss starts increasing\n",
    "        if prev_loss is not None and loss > prev_loss:\n",
    "            losses.pop() # discard the last guess since it performed worse \n",
    "            thetas.pop()\n",
    "            break\n",
    "            \n",
    "        # store for graphing\n",
    "        thetas.append(theta)\n",
    "        losses.append(loss)\n",
    "\n",
    "        prev_loss = loss\n",
    "        theta += step_size\n",
    "\n",
    "    return thetas, losses, i\n",
    "\n",
    "# ------------------------------------------------\n",
    "#                 main program\n",
    "# ------------------------------------------------\n",
    "# target distribution\n",
    "t_dist = {'00': 0.3, '11': 0.7} \n",
    "thetas, losses, iter = basic_optimizer(l2_loss, t_dist)\n",
    "\n",
    "# plot results\n",
    "plt.plot(thetas, losses, marker='o')\n",
    "plt.xlabel(\"θ\")\n",
    "plt.ylabel(\"L2 Loss\")\n",
    "plt.title(\"Loss vs θ\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# display circuit and results with final paramter\n",
    "model_dist = vqc(thetas[-1], True)\n",
    "display(\n",
    "    plot_distribution(\n",
    "        [t_dist, model_dist],\n",
    "        title=\"Target vs Model Distribution\",\n",
    "        legend=[\"Target (requested)\", \"Model\"]\n",
    "    )\n",
    ")\n",
    "print(f\"Optimization finished after {iter} iterations with θ = {thetas[-1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-2.0.2",
   "language": "python",
   "name": "qiskit-2.0.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
