{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a29b27",
   "metadata": {},
   "source": [
    "## QCLab: 3-Qubit Quantum Born Machine Trained on Target Probabilities\n",
    "\n",
    "A **Quantum Born Machine (QBM)** is a generative quantum machine learning model that learns probability distributions using the Born rule. The QBM is given a target distribution and must adjust its quantum circuit parameters so that the distribution of its measurement outcomes becomes similar to the given one. This lab is an expansion of the \"Minimal 2-qubit QBM\" lab to three qubits. The simple naive minimization used earlier is now replaced with the COBYLA optimizer from the SciPy library. This setup is closer to a real situation, where only the target probabilities are given, without access to the required results.\n",
    "In this particular example, the probability distribution represents the number of customers visiting a small coffee shop each hour over an 8-hour day. The goal is to simulate this traffic pattern using a quantum Born machine.  \n",
    "\n",
    "![3-qubit-QBM](images/3-qubit-QBM.png)\n",
    "\n",
    "In this particular example, the probability distribution represents the number of customers visiting a small coffee shop each hour over an 8-hour day, given as \n",
    "$p_{\\text{dist}} = [0.25, 0.18, 0.09, 0.04, 0.04, 0.09, 0.18, 0.25]$\n",
    "The goal is to simulate this traffic pattern using a quantum Born machine. To be able to achieve this, the given distribution is assigned to the 3-bit strings in binary order corresponding the given probability.\n",
    "\n",
    "---\n",
    "\n",
    "### Sampling, Model Distribution and Optimization\n",
    "\n",
    "The model distribution $p_{\\text{model}}$ is obtained by running the circuit multiple times (`sample_qbm(theta, shots=1000)`) on a simulator and normalizing counts:\n",
    "\n",
    "$$p_{\\text{model}}(x) = \\frac{\\text{counts}(x)}{\\sum_{y}\\text{counts}(y)}$$  \n",
    "\n",
    "where $x$ is a bitstring representing measurement outcomes. \n",
    "\n",
    "To compare the learned distribution with the target, we use the L2 loss (squared error), defined as:\n",
    "\n",
    "$$L_2(\\theta) = \\sum_{x \\in \\{0,1\\}^3} \\big( p_{\\text{target}}(x) - p_{\\text{model}}(x) \\big)^2$$  \n",
    "\n",
    "Optimization proceeds as follows:  \n",
    "- Start with random parameters `theta0`.  \n",
    "- Use the COBYLA optimizer from SciPy to minimize the loss $L(\\theta)$.  \n",
    "- Obtain the optimized parameters `theta_opt`.  \n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "- Implement a 3-qubit Quantum Born Machine (QBM) that learns a given target probability distribution.  \n",
    "- Construct a parameterized circuit using $R_y(\\theta)$ rotations and entangling CNOT gates.  \n",
    "- Train the circuit with the COBYLA optimizer from SciPy using only the target probabilities.  \n",
    "- Simulate the resulting circuit to approximate the target distribution representing customer visits to a coffee shop over 8 hours.  \n",
    "\n",
    "---\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "- A plot of the QBM circuit with optimized rotation angles.  \n",
    "- Overlayed bar plots comparing the target distribution $p_{\\text{target}}$ and the model distribution $p_{\\text{model}}$ for a visual check of fit.  \n",
    "- Printed results of the optimization, including the optimized parameters `theta_opt`.  \n",
    "\n",
    "---\n",
    "\n",
    "### Experimentation\n",
    "\n",
    "- Try different initial values of `theta0` to observe how the optimizer converges.  \n",
    "- Compare the effects of using L1 vs L2 loss functions on the final learned distribution.  \n",
    "- Vary the number of shots in `sample_qbm` to see how sampling noise influences the accuracy of the model distribution.  \n",
    "- Extend the circuit by adding more entangling gates or depth to explore how expressivity affects learning.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# QCLab: 3-Qubit Quantum Born Machine \n",
    "#        Trained on Target Probabilities\n",
    "# <QC|CT> qcict.org\n",
    "# ====================================================\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.visualization import plot_distribution\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# -- given target distribution --\n",
    "p_dist = [0.25, 0.18, 0.09, 0.04, 0.04, 0.09, 0.18, 0.25]\n",
    "\n",
    "# -- assign probabilities to 3-bit strings --\n",
    "p_target = {format(i, '03b'): p for i, p in enumerate(p_dist)}\n",
    "\n",
    "# -- create a QBM circuit with 3 parameters --\n",
    "def create_qbm_circuit(theta):\n",
    "    qc = QuantumCircuit(3)\n",
    "    for i in range(3):\n",
    "        qc.ry(theta[i], i)\n",
    "    qc.cx(0, 1)\n",
    "    qc.cx(1, 2)\n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "# -- sample from the QBM circuit --\n",
    "def sample_qbm(theta, shots=1000):\n",
    "    qc = create_qbm_circuit(theta)\n",
    "    simulator = AerSimulator()\n",
    "    result = simulator.run(qc, shots=shots).result()\n",
    "    counts = result.get_counts()\n",
    "    \n",
    "    # normalize counts to get model distribution\n",
    "    total = sum(counts.values())\n",
    "    p_model = {}\n",
    "    for bitstring, count in counts.items():\n",
    "        p_model[bitstring] = count / total\n",
    "    return p_model\n",
    "\n",
    "# -- define L2 loss function for optimizer --\n",
    "def l2_loss(theta):\n",
    "    p_model = sample_qbm(theta)\n",
    "    return sum((p_target[k] - p_model.get(k, 0)) ** 2 for k in p_target)\n",
    "\n",
    "# -----------------------------------------------\n",
    "#                main program\n",
    "# -----------------------------------------------\n",
    "\n",
    "# -- run optimization loop --\n",
    "theta0 = np.random.uniform(0, 2 * np.pi, 6)\n",
    "result = minimize(l2_loss, theta0, method='COBYLA')\n",
    "theta_opt = result.x\n",
    "\n",
    "# -- sample final QBM output --\n",
    "p_qbm = sample_qbm(theta_opt)\n",
    "\n",
    "# -- plot the circuit with optimized angles --\n",
    "qc = create_qbm_circuit(theta_opt)\n",
    "display(circuit_drawer(qc, style=\"bw\", output=\"mpl\"))\n",
    "\n",
    "# map bitstrings -> hour labels\n",
    "hour = {\n",
    "    '000': 'Hour 1', '001': 'Hour 2', '010': 'Hour 3', '011': 'Hour 4',\n",
    "    '100': 'Hour 5', '101': 'Hour 6', '110': 'Hour 7', '111': 'Hour 8'\n",
    "}\n",
    "\n",
    "display(plot_distribution(\n",
    "    [{hour.get(k, k): v for k, v in d.items()} for d in [p_target, p_qbm]], \n",
    "    legend=[\"Target\", \"Model\"], title=\"Coffee Shop Traffic\", bar_labels=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-2.0.2",
   "language": "python",
   "name": "qiskit-2.0.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
